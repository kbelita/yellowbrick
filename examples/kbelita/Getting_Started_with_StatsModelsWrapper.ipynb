{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with Yellowbrick's Regression Visualizations with StatsModels Wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This is an quick tutorial on getting started with [Yellowbrick's StatsModels Wrapper](http://www.scikit-yb.org/en/develop/api/contrib/statsmodels.html?highlight=statsmodels), for  those who like using StatModels and want to explore Yellowbrick, or for those who would like to explore both. Since Yellowbrick uses Scikit-Learn, this wrapper gives users the opportunity to extend Yellowbrick to StatsModels.\n",
    "\n",
    "\n",
    "#### **Just a few things before getting started...**\n",
    "\n",
    "**What is [Yellowbrick](http://www.scikit-yb.org/en/latest/)**?\n",
    ">*Yellowbrick* is a suite of visual diagnostic tools called “Visualizers” that extend the Scikit-Learn API to allow human steering of the model selection process. In a nutshell, Yellowbrick combines Scikit-Learn with Matplotlib in the best tradition of the Scikit-Learn documentation, but to produce visualizations for your models! \n",
    "\n",
    "**How to get started with Yellowbrick?**\n",
    ">Visit Yellowbrick's [Quick Start](http://www.scikit-yb.org/en/latest/quickstart.html) page, for installation instructions, API information and walkthrough examples.  \n",
    "\n",
    "**Yellowbrick Visualizers**\n",
    "> Visualizers are estimators (objects that learn from data) whose primary objective is to create visualizations that allow insight into the model selection process. In Scikit-Learn terms, they can be similar to transformers when visualizing the data space or wrap an model estimator similar to how the “ModelCV” (e.g. RidgeCV, LassoCV) methods work. The primary goal of Yellowbrick is to create a sensical API similar to Scikit-Learn. Some of our most popular visualizers include:\n",
    "\n",
    ">**Feature Visualization**\n",
    "* Rank Features: pairwise ranking of features to detect relationships\n",
    "* Parallel Coordinates: horizontal visualization of instances\n",
    "* Radial Visualization: separation of instances around a circular plot\n",
    "* PCA Projection: projection of instances based on principal components\n",
    "* Feature Importances: rank features by importance or linear coefficients for a specific model\n",
    "* Scatter and Joint Plots: direct data visualization with feature selection  \n",
    "\n",
    ">**Classification Visualization**\n",
    "* Class Balance: see how the distribution of classes affects the model\n",
    "* Class Prediction Error: shows error and support in classification\n",
    "* Classification Report: visual representation of precision, recall, and F1\n",
    "* ROC/AUC Curves: receiver operator characteristics and area under the curve\n",
    "* Confusion Matrices: visual description of class decision making  \n",
    "\n",
    ">**Regression Visualization**\n",
    "* Prediction Error Plot: find model breakdowns along the domain of the target\n",
    "* Residuals Plot: show the difference in residuals of training and test data\n",
    "* Alpha Selection: show how the choice of alpha influences regularization  \n",
    "\n",
    ">**Clustering Visualization**\n",
    "* K-Elbow Plot: select k using the elbow method and various metrics\n",
    "* Silhouette Plot: select k by visualizing silhouette coefficient values \n",
    "\n",
    "> **Text Visualization**\n",
    "* Term Frequency: visualize the frequency distribution of terms in the corpus\n",
    "* t-SNE Corpus Visualization: use stochastic neighbor embedding to project documents.\n",
    "\n",
    "\n",
    ">… and more! Visualizers are being added all the time; be sure to check the examples (or even the develop branch) and feel free to contribute your ideas for new Visualizers!\n",
    "\n",
    "**What is the StatsModelsWrapper?**\n",
    "> It is a basic wrapper for statsmdoels that emulates a scikit-learn estimator. *This wraps a statsmodels GLM as a sklearn (fake) BaseEstimator for Yellowbrick.*\n",
    "\n",
    "\n",
    "\n",
    "**This tutorial... **\n",
    "- uses the concrete dataset from Yellowbrick's Example Datasets, which are from the [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/),\n",
    "- shows some of Yellowbrick's feature visualizations and regression visualizations,\n",
    "- shows how to get started with the StatsModels Wrapper from Yellowbrick."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's import Yellowbrick and load the concrete dataset\n",
    "\n",
    "Below is from the Example Datasets [documentation](http://www.scikit-yb.org/en/develop/api/datasets.html).  \n",
    "\n",
    "First, the data must be downloaded, for accessibility, download it in your current directory using the terminal.\n",
    "\n",
    "\n",
    "```bash\n",
    "    $ python -m yellowbrick.download \n",
    "```\n",
    "\n",
    "This creates a directory named \"data\" with all the example datasets. For this tutorial, the conrete dataset must be downloaded using pandas.\n",
    "\n",
    "**For the purpose of this tutorial, the target is \"strength\" of concrete.**  \n",
    "Check out the [Concrete Data](https://archive.ics.uci.edu/ml/datasets/Concrete+Compressive+Strength) from the UCI Machine Learning Repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data/concrete/concrete.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating to Yellowbrick Visualizers\n",
    "\n",
    "Yellowbrick visualizers act as a transformer to fit the `Visualizer` (or the model with the visualizer) a la Scikit-Learn workflow. This will make using scikit-learn easier, and in perspective the StatsModels Wrapper. \n",
    "\n",
    "As the workflow goes:\n",
    "- import the visualizer\n",
    "- call the `fit()` method to instantiate the visualizer\n",
    "- call the `poof()` method for rendering the image!\n",
    "\n",
    "Such as:\n",
    "```python\n",
    "from yellowbrick.features import ParallelCoordinates\n",
    "visualizer = ParallelCoordinates()\n",
    "visualizer.fit_transform(X, y)\n",
    "visualizer.poof()\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to Rank Features and Joint Plot Visualizations \n",
    "(Two of yellowbrick's visualizations, there are many more!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank Features\n",
    "\n",
    "These [rank feature visualizations](http://www.scikit-yb.org/en/develop/api/features/rankd.html#rank-features) evaluate a single feature or a feature's relationship to another feature. \n",
    "\n",
    "#### *First*, **Rank1D**\n",
    "\n",
    ">This is a one dimensional ranking of features, the default of Rank1D is the Shapiro-Wilk algorithm which assesses the distribution of each instances in regards to each feature. This will show a bar plot for each feature. \n",
    "\n",
    "To start, load the features and target data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['cement', 'slag', 'ash', 'water', 'splast', 'coarse', 'fine', 'age']\n",
    "target = 'strength'\n",
    "\n",
    "X = data[features]\n",
    "y = data[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's see **Rank1D**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.features import Rank1D\n",
    "\n",
    "visualizer = Rank1D(features=features, algorithm='shapiro') #Instantiate the Visualizer\n",
    "\n",
    "visualizer.fit(X, y)                # Fit the data to the visualizer\n",
    "visualizer.transform(X)             # Transform the data\n",
    "visualizer.poof()                   # Draw/show/poof the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Then second*, **Rank2D**\n",
    "\n",
    ">This is a two dimensional ranking of features, which compares each feature to another, and creates a heatmap to represent the relationship. The default algorithm of Rank2D is the Pearson Correlation, the covariance algorithm is also available. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, load the features and target data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['cement', 'slag', 'ash', 'water', 'splast', 'coarse', 'fine', 'age']\n",
    "target = 'strength'\n",
    "\n",
    "X = data[features]\n",
    "y = data[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see **Rank2d**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.features import Rank2D\n",
    "\n",
    "visualizer = Rank2D(features=features, algorithm='pearson') #Instantiate the Visualizer\n",
    "\n",
    "visualizer.fit(X, y)                # Fit the data to the visualizer\n",
    "visualizer.transform(X)             # Transform the data\n",
    "visualizer.poof()                   # Draw/show/poof the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint Plot Visualization\n",
    "\n",
    ">The [joint plot visualization](http://www.scikit-yb.org/en/develop/api/features/scatter.html#joint-plot-visualization) will show the distribution of a features against the target.\n",
    "\n",
    "\n",
    "To start, load the features and target data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'water'\n",
    "target = 'strength'\n",
    "\n",
    "X = data[feature]\n",
    "y = data[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the **Joint Plot Visualizer**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.features import JointPlotVisualizer\n",
    "\n",
    "visualizer = JointPlotVisualizer(feature=feature, target=target) #Instantiate the Visualizer\n",
    "\n",
    "visualizer.fit(X, y)                # Fit the data to the visualizer\n",
    "visualizer.poof()                   # Draw/show/poof the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the StatsModelsWrapper\n",
    "\n",
    ">The purpose of this basic [statsmodels wrapper](http://www.scikit-yb.org/en/develop/api/contrib/statsmodels.html) is to be able to emulate the scikit-learn estimator and be able to utilize Yellowbrick visualizations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All that needs to be done is to import external libraries and instantiate the **statsmodel wrapper** with GLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm \n",
    "from functools import partial\n",
    "from yellowbrick.contrib.statsmodels import StatsModelsWrapper\n",
    "\n",
    "glm_gaussian_partial = partial(sm.GLM, family=sm.families.Gaussian()) # initiates a partial with statsmodels\n",
    "model = StatsModelsWrapper(glm_gaussian_partial) # wrapper the statsmodels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And that's it! Now the GLM from statsmodel is ready to be used for regression visualizers!**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Visualizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residuals Plot\n",
    "\n",
    "> The [residuals plot](http://www.scikit-yb.org/en/latest/api/regressor/residuals.html) shows residuals and the predicted values. If the points are randomly dispersed around the horizontal axis, a linear regression model is appropriate for the data; otherwise, a non-linear model is more appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, load the features and target data, then, create test and train data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = ['cement', 'slag', 'ash', 'water', 'splast', 'coarse', 'fine', 'age']\n",
    "target = 'strength'\n",
    "\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the model (here, the statsmodel GLM wrapped-up as a sklearn BaseEstimator) and visualizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import ResidualsPlot\n",
    "\n",
    "visualizer = ResidualsPlot(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the **Residuals Plot**!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "g = visualizer.poof()             # Draw/show/poof the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Error Plot\n",
    "\n",
    ">The [prediction error plot](http://www.scikit-yb.org/en/latest/api/regressor/peplot.html) shows the actual target values to the predicted values generated by the model we selected (here, the statsmodels GLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, load the features and target data, then, create test and train data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = ['cement', 'slag', 'ash', 'water', 'splast', 'coarse', 'fine', 'age']\n",
    "target = 'strength'\n",
    "\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the model (here, the statsmodel GLM wrapped-up as a sklearn BaseEstimator) and visualizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "\n",
    "visualizer = PredictionError(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the **Prediction Error Plot**!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "g = visualizer.poof()             # Draw/show/poof the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  And that's how to get started with Yellowbrick's regression visualizations and statsmodels wrapper!\n",
    "\n",
    "Code and explanations in this tutorial are from the [Yellowbrick Documentation](http://www.scikit-yb.org/en/develop/index.html). \n",
    "\n",
    "**Check it out!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python envpy3",
   "language": "python",
   "name": "envpy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
